<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>cnlp.other_methods.information_theory API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cnlp.other_methods.information_theory</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import networkx as nx
import numpy as np
import scipy.sparse as scipy
import math
import itertools
from cnlp.utils import nodes_to_indexes
from scipy.sparse import lil_matrix, csr_matrix
from typing import Generator


def MI(G: nx.Graph) -&gt; scipy.csr_matrix:
    &#34;&#34;&#34;Neighbor Set Information

    Il modello di link prediction basato su information theory che sfrutta la neighbor
    set information è un approccio utilizzato per prevedere la probabilità di esistenza
    di un link tra due nodi in una rete. In questo modello, l&#39;informazione contenuta nei
    neighbor set dei due nodi in questione viene utilizzata per stimare la probabilità
    di connessione.

    L&#39;idea alla base di questo modello è che i nodi che hanno molti neighbor in comune
    sono più propensi a essere connessi tra loro rispetto a nodi con neighbor set diversi.
    Questo perché i nodi con neighbor set simili tendono a essere coinvolti in attività
    simili all&#39;interno della rete, come ad esempio
    partecipare agli stessi gruppi o condividere gli stessi interessi.

    Per utilizzare questa informazione per prevedere la probabilità di connessione tra due nodi,
    il modello utilizza l&#39;entropia di Shannon, una misura dell&#39;incertezza di una
    distribuzione di probabilità.
    In particolare, l&#39;entropia viene calcolata sui neighbor set dei due nodi, e la differenza tra le
    entropie dei due set viene utilizzata per stimare la probabilità di connessione.

    Parameters
    ----------
    G: nx.Graph :
        input Graph (a networkx Graph)

    Returns
    -------
    res_sparse: csr_matrix : the Similarity Matrix (in sparse format)
    &#34;&#34;&#34;

    def overlap_info(G: nx.Graph, x, y, edge_num: int) -&gt; float:
        &#34;&#34;&#34;Two Information Definition.
        Overlapping nodes of different sets and
        the existence of link across different sets

        Parameters
        ----------
        G: nx.Graph :
            input graph
        x :
            first node
        y :
            second node
        edge_num: int :
            TODO !

        Returns
        -------
        s_Overlap: float : TODO
        &#34;&#34;&#34;
        # ottenimento dei dati da cui ottenere le informazioni
        o_nodes = nx.common_neighbors(G, x, y)
        p_prob_overlap = -np.log2(prior(x, y, G, edge_num))

        # utilizzo delle informazioni per stimarsi la likelihood
        # con gli overlapping nodes
        coeff = 0
        overlap_info_value = 0
        overlap = 0

        for z in o_nodes:
            # degree of z
            kz = G.degree(z)

            coeff = 1 / (kz * (kz - 1))

            # sum over edges = neighbors of z
            overlap = 0
            for m, n in itertools.combinations(G.neighbors(z), 2):
                priorInfo = -np.log2(prior(m, n, G, edge_num))
                likelihoodInfo = -np.log2(likelihood(z, G))
                # print(f&#34;a = {x}, b = {y}, priorInfo = { priorInfo},
                #   lilelihoodInfo = {likelihoodInfo}&#34;)
                # combine mutual information
                overlap += 2 * (priorInfo - likelihoodInfo)
                # print(f&#34;a = {x}, b = {y}, zOverlap = { 2*(priorInfo -likelihoodInfo)}&#34;)

        # add average mutual information per neighbor
        overlap_info_value += coeff * overlap
        s_Overlap = overlap_info_value - p_prob_overlap
        return s_Overlap

    def prior(m, n, G: nx.Graph, edge_num: int) -&gt; float:
        &#34;&#34;&#34;Calcola la probabilità a priori dati due nodi e
        un grafo riferita alla probabilità con cui non si forma un cammino
        tra i due nodi

        Parameters
        ----------
        m :
            first node
        n :
            second node
        G: nx.Graph :
            input graph
        edge_num: int :
            TODO

        Returns
        -------
        float: the prior probability
        &#34;&#34;&#34;
        kn = G.degree(n)
        km = G.degree(m)

        return 1 - math.comb(edge_num - kn, km) / math.comb(edge_num, km)

    def likelihood(z, G: nx.Graph) -&gt; float:
        &#34;&#34;&#34;probabilità condizionata che in questo caso è definita come il clustering
        coefficient dei common neighbor dei nodi x e y

        Parameters
        ----------
        z :
            input node
        G: nx.Graph :
            input graph

        Returns
        -------
        float: TODO
        &#34;&#34;&#34;
        kz = G.degree(z)
        N_triangles = nx.triangles(G, z)
        N_triads = math.comb(kz, 2)

        return N_triangles / N_triads

    I_Oxy = 0
    edge_num = G.number_of_edges()
    node_num = G.number_of_nodes()
    edge_num = G.number_of_edges()
    res_sparse = scipy.lil_matrix((node_num, node_num))

    nodes_to_indexes_map = nodes_to_indexes(G)
    for i, j in nx.complement(G).edges():
        I_Oxy = overlap_info(G, i, j, edge_num)
        res_sparse[nodes_to_indexes_map[i], nodes_to_indexes_map[j]] = I_Oxy

    return res_sparse.tocsr()


def path_entropy(G: nx.Graph, max_path: int = 3) -&gt; csr_matrix:
    &#34;&#34;&#34;Compute the Path Entropy Measure for all nodes in the Graph.

    This Similarity measure between two nodes \\(X\\) and \\(Y\\)
    is calculated with:

    .. math::
        S_{x,y} = -I(L^1_{xy}|U_{i=2}^{maxlen} D_{xy}^i)

    where \\(D^i_{xy}\\) represents the set consisting of all simple
    paths of length i between the two vertices and maxlen is the maximum
    length of simple path of the network.

    Parameters
    ----------
    G: nx.Graph :
        input Graph (a networkx Graph)
    max_path: int :
        maximal path length
         (Default value = 3)

    Returns
    -------
    similarity_matrix: csr_matix: the Similarity Matrix (in sparse format)
    &#34;&#34;&#34;

    def simple_path_entropy(paths: Generator[list, None, None],
                            G: nx.Graph) -&gt; float:
        &#34;&#34;&#34;Calcola l&#39;entropia data dalla probabilità che si vengano a creare
        i vari simple paths tra i nodi tra cui si
        vuole fare link prediction

        Parameters
        ----------
        paths: Generator[List] :
            generator ritornato dalla funzione nx.all_simple_paths()

        G: nx.Graph :
            input graph

        Returns
        -------
        float: simple path entropy
        &#34;&#34;&#34;
        tmp = .0
        for path in paths:
            for a, b in list(nx.utils.pairwise(path)):
                tmp += new_link_entropy(G, a, b)
        return tmp

    def new_link_entropy(G: nx.Graph, a, b) -&gt; float:
        &#34;&#34;&#34;Calcola l&#39;entropia basata sulla probabilità
        a priori della creazione del link diretto
        tra le coppie di noti senza link diretti

        Parameters
        ----------
        G: nx.Graph :
            input graph
        a :
            first node
        b :
            second node

        Returns
        -------
        float: entropy between node A and B
        &#34;&#34;&#34;
        deg_a = G.degree(a)
        deg_b = G.degree(b)
        M = G.number_of_edges()

        return -1 * math.log2(1 - (math.comb(M - deg_a, deg_b) /
                                   math.comb(M, deg_b)))

    similarity_matrix = lil_matrix((G.number_of_nodes(), G.number_of_nodes()))
    nodes_to_indexes_map = nodes_to_indexes(G)
    missing_edges = list(nx.complement(G).edges())

    for elem in missing_edges:
        paths = nx.all_simple_paths(G, elem[0], elem[1], max_path)
        tmp = 0
        for i in range(2, (max_path + 1)):
            tmp += (1 / (i - 1)) * simple_path_entropy(paths=paths, G=G)
        tmp = tmp - new_link_entropy(G, elem[0], elem[1])
        similarity_matrix[nodes_to_indexes_map[elem[0]],
                          nodes_to_indexes_map[elem[1]]] = tmp
    return similarity_matrix.tocsr()


if __name__ == &#34;__main__&#34;:
    import matplotlib.pyplot as plt

    G = nx.karate_club_graph()

    # converte gli id dei nodi in interi affinche possano essere usati come indici
    # G_to_int = nx.convert_node_labels_to_integers(G, 0)
    nx.draw(G, with_labels=True)

    ranking = MI(G)
    # da aggiungere informazioni dei nodi che hanno fatto ottentere il
    # ranking migliore

    # va preso il risultato più piccolo perchè si tratta di entropia
    print(ranking)
    for i, j in nx.complement(G).edges():
        if (ranking[i, j] == ranking.toarray().min()):
            print(
                f&#34;Il link più probabile tra quelli possibili è tra {i} e {j}, con un valore di {ranking[i,j]}&#34;
            )
    plt.show()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="cnlp.other_methods.information_theory.MI"><code class="name flex">
<span>def <span class="ident">MI</span></span>(<span>G: networkx.classes.graph.Graph) ‑> scipy.sparse._csr.csr_matrix</span>
</code></dt>
<dd>
<div class="desc"><p>Neighbor Set Information</p>
<p>Il modello di link prediction basato su information theory che sfrutta la neighbor
set information è un approccio utilizzato per prevedere la probabilità di esistenza
di un link tra due nodi in una rete. In questo modello, l'informazione contenuta nei
neighbor set dei due nodi in questione viene utilizzata per stimare la probabilità
di connessione.</p>
<p>L'idea alla base di questo modello è che i nodi che hanno molti neighbor in comune
sono più propensi a essere connessi tra loro rispetto a nodi con neighbor set diversi.
Questo perché i nodi con neighbor set simili tendono a essere coinvolti in attività
simili all'interno della rete, come ad esempio
partecipare agli stessi gruppi o condividere gli stessi interessi.</p>
<p>Per utilizzare questa informazione per prevedere la probabilità di connessione tra due nodi,
il modello utilizza l'entropia di Shannon, una misura dell'incertezza di una
distribuzione di probabilità.
In particolare, l'entropia viene calcolata sui neighbor set dei due nodi, e la differenza tra le
entropie dei due set viene utilizzata per stimare la probabilità di connessione.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>G</code></strong> :&ensp;<code>nx.Graph :</code></dt>
<dd>input Graph (a networkx Graph)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>res_sparse</code></strong> :&ensp;<code>csr_matrix : the Similarity Matrix (in sparse format)</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def MI(G: nx.Graph) -&gt; scipy.csr_matrix:
    &#34;&#34;&#34;Neighbor Set Information

    Il modello di link prediction basato su information theory che sfrutta la neighbor
    set information è un approccio utilizzato per prevedere la probabilità di esistenza
    di un link tra due nodi in una rete. In questo modello, l&#39;informazione contenuta nei
    neighbor set dei due nodi in questione viene utilizzata per stimare la probabilità
    di connessione.

    L&#39;idea alla base di questo modello è che i nodi che hanno molti neighbor in comune
    sono più propensi a essere connessi tra loro rispetto a nodi con neighbor set diversi.
    Questo perché i nodi con neighbor set simili tendono a essere coinvolti in attività
    simili all&#39;interno della rete, come ad esempio
    partecipare agli stessi gruppi o condividere gli stessi interessi.

    Per utilizzare questa informazione per prevedere la probabilità di connessione tra due nodi,
    il modello utilizza l&#39;entropia di Shannon, una misura dell&#39;incertezza di una
    distribuzione di probabilità.
    In particolare, l&#39;entropia viene calcolata sui neighbor set dei due nodi, e la differenza tra le
    entropie dei due set viene utilizzata per stimare la probabilità di connessione.

    Parameters
    ----------
    G: nx.Graph :
        input Graph (a networkx Graph)

    Returns
    -------
    res_sparse: csr_matrix : the Similarity Matrix (in sparse format)
    &#34;&#34;&#34;

    def overlap_info(G: nx.Graph, x, y, edge_num: int) -&gt; float:
        &#34;&#34;&#34;Two Information Definition.
        Overlapping nodes of different sets and
        the existence of link across different sets

        Parameters
        ----------
        G: nx.Graph :
            input graph
        x :
            first node
        y :
            second node
        edge_num: int :
            TODO !

        Returns
        -------
        s_Overlap: float : TODO
        &#34;&#34;&#34;
        # ottenimento dei dati da cui ottenere le informazioni
        o_nodes = nx.common_neighbors(G, x, y)
        p_prob_overlap = -np.log2(prior(x, y, G, edge_num))

        # utilizzo delle informazioni per stimarsi la likelihood
        # con gli overlapping nodes
        coeff = 0
        overlap_info_value = 0
        overlap = 0

        for z in o_nodes:
            # degree of z
            kz = G.degree(z)

            coeff = 1 / (kz * (kz - 1))

            # sum over edges = neighbors of z
            overlap = 0
            for m, n in itertools.combinations(G.neighbors(z), 2):
                priorInfo = -np.log2(prior(m, n, G, edge_num))
                likelihoodInfo = -np.log2(likelihood(z, G))
                # print(f&#34;a = {x}, b = {y}, priorInfo = { priorInfo},
                #   lilelihoodInfo = {likelihoodInfo}&#34;)
                # combine mutual information
                overlap += 2 * (priorInfo - likelihoodInfo)
                # print(f&#34;a = {x}, b = {y}, zOverlap = { 2*(priorInfo -likelihoodInfo)}&#34;)

        # add average mutual information per neighbor
        overlap_info_value += coeff * overlap
        s_Overlap = overlap_info_value - p_prob_overlap
        return s_Overlap

    def prior(m, n, G: nx.Graph, edge_num: int) -&gt; float:
        &#34;&#34;&#34;Calcola la probabilità a priori dati due nodi e
        un grafo riferita alla probabilità con cui non si forma un cammino
        tra i due nodi

        Parameters
        ----------
        m :
            first node
        n :
            second node
        G: nx.Graph :
            input graph
        edge_num: int :
            TODO

        Returns
        -------
        float: the prior probability
        &#34;&#34;&#34;
        kn = G.degree(n)
        km = G.degree(m)

        return 1 - math.comb(edge_num - kn, km) / math.comb(edge_num, km)

    def likelihood(z, G: nx.Graph) -&gt; float:
        &#34;&#34;&#34;probabilità condizionata che in questo caso è definita come il clustering
        coefficient dei common neighbor dei nodi x e y

        Parameters
        ----------
        z :
            input node
        G: nx.Graph :
            input graph

        Returns
        -------
        float: TODO
        &#34;&#34;&#34;
        kz = G.degree(z)
        N_triangles = nx.triangles(G, z)
        N_triads = math.comb(kz, 2)

        return N_triangles / N_triads

    I_Oxy = 0
    edge_num = G.number_of_edges()
    node_num = G.number_of_nodes()
    edge_num = G.number_of_edges()
    res_sparse = scipy.lil_matrix((node_num, node_num))

    nodes_to_indexes_map = nodes_to_indexes(G)
    for i, j in nx.complement(G).edges():
        I_Oxy = overlap_info(G, i, j, edge_num)
        res_sparse[nodes_to_indexes_map[i], nodes_to_indexes_map[j]] = I_Oxy

    return res_sparse.tocsr()</code></pre>
</details>
</dd>
<dt id="cnlp.other_methods.information_theory.path_entropy"><code class="name flex">
<span>def <span class="ident">path_entropy</span></span>(<span>G: networkx.classes.graph.Graph, max_path: int = 3) ‑> scipy.sparse._csr.csr_matrix</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the Path Entropy Measure for all nodes in the Graph.</p>
<p>This Similarity measure between two nodes <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> and <span><span class="MathJax_Preview">Y</span><script type="math/tex">Y</script></span>
is calculated with:</p>
<p><span><span class="MathJax_Preview"> S_{x,y} = -I(L^1_{xy}|U_{i=2}^{maxlen} D_{xy}^i) </span><script type="math/tex; mode=display"> S_{x,y} = -I(L^1_{xy}|U_{i=2}^{maxlen} D_{xy}^i) </script></span>
where <span><span class="MathJax_Preview">D^i_{xy}</span><script type="math/tex">D^i_{xy}</script></span> represents the set consisting of all simple
paths of length i between the two vertices and maxlen is the maximum
length of simple path of the network.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>G</code></strong> :&ensp;<code>nx.Graph :</code></dt>
<dd>input Graph (a networkx Graph)</dd>
<dt><strong><code>max_path</code></strong> :&ensp;<code>int :</code></dt>
<dd>maximal path length
(Default value = 3)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>similarity_matrix</code></strong> :&ensp;<code>csr_matix: the Similarity Matrix (in sparse format)</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def path_entropy(G: nx.Graph, max_path: int = 3) -&gt; csr_matrix:
    &#34;&#34;&#34;Compute the Path Entropy Measure for all nodes in the Graph.

    This Similarity measure between two nodes \\(X\\) and \\(Y\\)
    is calculated with:

    .. math::
        S_{x,y} = -I(L^1_{xy}|U_{i=2}^{maxlen} D_{xy}^i)

    where \\(D^i_{xy}\\) represents the set consisting of all simple
    paths of length i between the two vertices and maxlen is the maximum
    length of simple path of the network.

    Parameters
    ----------
    G: nx.Graph :
        input Graph (a networkx Graph)
    max_path: int :
        maximal path length
         (Default value = 3)

    Returns
    -------
    similarity_matrix: csr_matix: the Similarity Matrix (in sparse format)
    &#34;&#34;&#34;

    def simple_path_entropy(paths: Generator[list, None, None],
                            G: nx.Graph) -&gt; float:
        &#34;&#34;&#34;Calcola l&#39;entropia data dalla probabilità che si vengano a creare
        i vari simple paths tra i nodi tra cui si
        vuole fare link prediction

        Parameters
        ----------
        paths: Generator[List] :
            generator ritornato dalla funzione nx.all_simple_paths()

        G: nx.Graph :
            input graph

        Returns
        -------
        float: simple path entropy
        &#34;&#34;&#34;
        tmp = .0
        for path in paths:
            for a, b in list(nx.utils.pairwise(path)):
                tmp += new_link_entropy(G, a, b)
        return tmp

    def new_link_entropy(G: nx.Graph, a, b) -&gt; float:
        &#34;&#34;&#34;Calcola l&#39;entropia basata sulla probabilità
        a priori della creazione del link diretto
        tra le coppie di noti senza link diretti

        Parameters
        ----------
        G: nx.Graph :
            input graph
        a :
            first node
        b :
            second node

        Returns
        -------
        float: entropy between node A and B
        &#34;&#34;&#34;
        deg_a = G.degree(a)
        deg_b = G.degree(b)
        M = G.number_of_edges()

        return -1 * math.log2(1 - (math.comb(M - deg_a, deg_b) /
                                   math.comb(M, deg_b)))

    similarity_matrix = lil_matrix((G.number_of_nodes(), G.number_of_nodes()))
    nodes_to_indexes_map = nodes_to_indexes(G)
    missing_edges = list(nx.complement(G).edges())

    for elem in missing_edges:
        paths = nx.all_simple_paths(G, elem[0], elem[1], max_path)
        tmp = 0
        for i in range(2, (max_path + 1)):
            tmp += (1 / (i - 1)) * simple_path_entropy(paths=paths, G=G)
        tmp = tmp - new_link_entropy(G, elem[0], elem[1])
        similarity_matrix[nodes_to_indexes_map[elem[0]],
                          nodes_to_indexes_map[elem[1]]] = tmp
    return similarity_matrix.tocsr()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cnlp.other_methods" href="index.html">cnlp.other_methods</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="cnlp.other_methods.information_theory.MI" href="#cnlp.other_methods.information_theory.MI">MI</a></code></li>
<li><code><a title="cnlp.other_methods.information_theory.path_entropy" href="#cnlp.other_methods.information_theory.path_entropy">path_entropy</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>